{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d173213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\merry\\anaconda\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in c:\\users\\merry\\anaconda\\lib\\site-packages (from pyspark) (0.10.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3c8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "from random import random\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "from pyspark.mllib.stat import Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98255ed",
   "metadata": {},
   "source": [
    "### 1. Extract,Load data,Read data as text files as RDD Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d2f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").\\\n",
    "        appName(\"SparkApplication\").\\\n",
    "        config(\"spark.driver.bindAddress\",\"localhost\").\\\n",
    "        config(\"spark.ui.port\",\"4041\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9f950f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-6ID7C824:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkApplication</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f293254eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a537f",
   "metadata": {},
   "source": [
    "#### To read CSV in Spark into single RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44dc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663246a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.read csv file in rdd\n",
    "data=sc.textFile(\"C:/Users/merry/Desktop/churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd78c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " C:/Users/merry/Desktop/churn.csv MapPartitionsRDD[3] at textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "print('\\n',data) #what file rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe8a919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print('\\n',type(data)) # variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c53bb2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['__add__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_computeFractionForSampleSize', '_defaultReducePartitions', '_id', '_is_barrier', '_jrdd', '_jrdd_deserializer', '_memory_limit', '_pickled', '_reserialize', '_to_java_object_rdd', 'aggregate', 'aggregateByKey', 'barrier', 'cache', 'cartesian', 'checkpoint', 'coalesce', 'cogroup', 'collect', 'collectAsMap', 'collectWithJobGroup', 'combineByKey', 'context', 'count', 'countApprox', 'countApproxDistinct', 'countByKey', 'countByValue', 'ctx', 'distinct', 'filter', 'first', 'flatMap', 'flatMapValues', 'fold', 'foldByKey', 'foreach', 'foreachPartition', 'fullOuterJoin', 'getCheckpointFile', 'getNumPartitions', 'getResourceProfile', 'getStorageLevel', 'glom', 'groupBy', 'groupByKey', 'groupWith', 'has_resource_profile', 'histogram', 'id', 'intersection', 'isCheckpointed', 'isEmpty', 'isLocallyCheckpointed', 'is_cached', 'is_checkpointed', 'join', 'keyBy', 'keys', 'leftOuterJoin', 'localCheckpoint', 'lookup', 'map', 'mapPartitions', 'mapPartitionsWithIndex', 'mapPartitionsWithSplit', 'mapValues', 'max', 'mean', 'meanApprox', 'min', 'name', 'partitionBy', 'partitioner', 'persist', 'pipe', 'randomSplit', 'reduce', 'reduceByKey', 'reduceByKeyLocally', 'repartition', 'repartitionAndSortWithinPartitions', 'rightOuterJoin', 'sample', 'sampleByKey', 'sampleStdev', 'sampleVariance', 'saveAsHadoopDataset', 'saveAsHadoopFile', 'saveAsNewAPIHadoopDataset', 'saveAsNewAPIHadoopFile', 'saveAsPickleFile', 'saveAsSequenceFile', 'saveAsTextFile', 'setName', 'sortBy', 'sortByKey', 'stats', 'stdev', 'subtract', 'subtractByKey', 'sum', 'sumApprox', 'take', 'takeOrdered', 'takeSample', 'toDF', 'toDebugString', 'toLocalIterator', 'top', 'treeAggregate', 'treeReduce', 'union', 'unpersist', 'values', 'variance', 'withResources', 'zip', 'zipWithIndex', 'zipWithUniqueId']\n"
     ]
    }
   ],
   "source": [
    "print('\\n',dir(data))# what attributes are avaiable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a54d32b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID,gender,SeniorCitizen,Partner,Dependents,tenure,PhoneService,MultipleLines,InternetService,OnlineSecurity,OnlineBackup,DeviceProtection,TechSupport,StreamingTV,StreamingMovies,Contract,PaperlessBilling,PaymentMethod,MonthlyCharges,TotalCharges,Churn\n"
     ]
    }
   ],
   "source": [
    "#header\n",
    "header=data.first()\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feabea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove header\n",
    "rdd1= data.filter(lambda line: line !=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b7be75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " file has: 7043 row\n"
     ]
    }
   ],
   "source": [
    "#total record counts\n",
    "print('\\n file has:',rdd1.count(),'row') #counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e03e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " file line: 7590-VHVEG,Female,0,Yes,No,1,No,No phone service,DSL,No,Yes,No,No,No,No,Month-to-month,Yes,Electronic check,29.85,29.85,No\n"
     ]
    }
   ],
   "source": [
    "#filter first row\n",
    "print('\\n file line:',rdd1.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba4f53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7590-VHVEG,Female,0,Yes,No,1,No,No phone service,DSL,No,Yes,No,No,No,No,Month-to-month,Yes,Electronic check,29.85,29.85,No',\n",
       " '5575-GNVDE,Male,0,No,No,34,Yes,No,DSL,Yes,No,Yes,No,No,No,One year,No,Mailed check,56.95,1889.5,No',\n",
       " '3668-QPYBK,Male,0,No,No,2,Yes,No,DSL,Yes,Yes,No,No,No,No,Month-to-month,Yes,Mailed check,53.85,108.15,Yes',\n",
       " '7795-CFOCW,Male,0,No,No,45,No,No phone service,DSL,Yes,No,Yes,Yes,No,No,One year,No,Bank transfer (automatic),42.3,1840.75,No',\n",
       " '9237-HQITU,Female,0,No,No,2,Yes,No,Fiber optic,No,No,No,No,No,No,Month-to-month,Yes,Electronic check,70.7,151.65,Yes']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.take(5) #take file element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c4d1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7043"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total unique records count\n",
    "rdd1.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd11a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial partition count:1\n"
     ]
    }
   ],
   "source": [
    "print(\"initial partition count:\"+str(rdd1.getNumPartitions()))\n",
    "#Outputs: initial partition count:2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312359fd",
   "metadata": {},
   "source": [
    "#### Transform: Exploratory data analysis using rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce56d0",
   "metadata": {},
   "source": [
    "- replace Contract column values\n",
    "\n",
    "    - Month-to-month -1m\n",
    "\n",
    "    - One Year - 1y\n",
    "\n",
    "    - Two Year - 2y\n",
    "\n",
    "    - rest all - Others\n",
    "\n",
    "- Unique customer count\n",
    "\n",
    "- describe the categorical and numerical columns seperately\n",
    "\n",
    "- GroupBy contract and avg of totalcharges\n",
    "\n",
    "- using accumulator add the totalcharges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe4d31",
   "metadata": {},
   "source": [
    "#### Load: Save analysis report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a566640f",
   "metadata": {},
   "source": [
    "- GroupBy contract and avg of totalcharges save as files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb174a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step1= rdd1.map(lambda line: line.split(\",\")) # split by ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3112e9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['7590-VHVEG',\n",
       "  'Female',\n",
       "  '0',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  '1',\n",
       "  'No',\n",
       "  'No phone service',\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'Month-to-month',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  '29.85',\n",
       "  '29.85',\n",
       "  'No'],\n",
       " ['5575-GNVDE',\n",
       "  'Male',\n",
       "  '0',\n",
       "  'No',\n",
       "  'No',\n",
       "  '34',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'DSL',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'One year',\n",
       "  'No',\n",
       "  'Mailed check',\n",
       "  '56.95',\n",
       "  '1889.5',\n",
       "  'No']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f354eeec",
   "metadata": {},
   "source": [
    "### 2.Transform: Exploratory data analysis using rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd218f52",
   "metadata": {},
   "source": [
    "replace Contract column values\n",
    "\n",
    "Month-to-month -1m\n",
    "\n",
    "One Year - 1y\n",
    "\n",
    "Two Year - 2y\n",
    "\n",
    "rest all - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f602359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(column_val):\n",
    "    if column_val==\"Month-to-month\":\n",
    "        column_val=\"1m\"\n",
    "    elif column_val==\"One year\":\n",
    "        column_val=\"1y\"\n",
    "    elif column_val==\"Two year\":\n",
    "        column_val=\"2y\"\n",
    "    else:\n",
    "        column_val= \"Others\"\n",
    "    return column_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a54c204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step2=step1.map(lambda x: (x[0],x[1],x[2],x[3],x[4],x[5],\n",
    "                           x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],replace(x[15]),x[16],x[17],x[18],x[19],x[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d2919b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7590-VHVEG',\n",
       "  'Female',\n",
       "  '0',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  '1',\n",
       "  'No',\n",
       "  'No phone service',\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1m',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  '29.85',\n",
       "  '29.85',\n",
       "  'No'),\n",
       " ('5575-GNVDE',\n",
       "  'Male',\n",
       "  '0',\n",
       "  'No',\n",
       "  'No',\n",
       "  '34',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'DSL',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1y',\n",
       "  'No',\n",
       "  'Mailed check',\n",
       "  '56.95',\n",
       "  '1889.5',\n",
       "  'No')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step2.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b48098d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to convert numerical columns from string to int\n",
    "def string_to_int(val):\n",
    "    try:\n",
    "        return int(float(val))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72efb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "step3=step2.map(lambda x: (x[0],x[1],string_to_int(x[2]),x[3],x[4],string_to_int(x[5]),\n",
    "                           x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],x[15],x[16],x[17],string_to_int(x[18]),string_to_int(x[19]),x[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa495c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7590-VHVEG',\n",
       "  'Female',\n",
       "  0,\n",
       "  'Yes',\n",
       "  'No',\n",
       "  1,\n",
       "  'No',\n",
       "  'No phone service',\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1m',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  29,\n",
       "  29,\n",
       "  'No')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step3.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49d3ce",
   "metadata": {},
   "source": [
    "### 3. describe the categorical and numerical columns seperately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca3c2b",
   "metadata": {},
   "source": [
    "#### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fed0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data=step3.map(lambda x: (x[2],x[5],x[18],x[19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bed24a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 29, 29), (0, 34, 56, 1889), (0, 2, 53, 108), (0, 45, 42, 1840)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735029d",
   "metadata": {},
   "source": [
    "#### Maximum and minimum entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de711a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Maximum  entry  in each column (1, 72, 117, 8436)\n",
      "Minimum  entery  in each column (0, 0, 19, 0)\n"
     ]
    }
   ],
   "source": [
    "# decribe num\n",
    "print(\" Maximum  entry  in each column\",num_data.max())\n",
    "print(\"Minimum  entery  in each column\",num_data.min())\n",
    "#print(\"Mean numbers in each columns\",num_data.mean())\n",
    "#print(\"Standard deviation of each columns\", num_data.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b588d8c",
   "metadata": {},
   "source": [
    "#### Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d6102e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7590-VHVEG',\n",
       "  'Female',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  [7],\n",
       "  'DSL',\n",
       "  'No',\n",
       "  'Yes',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  'No',\n",
       "  '1m',\n",
       "  'Yes',\n",
       "  'Electronic check',\n",
       "  'No')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data=step3.map(lambda x:(x[0],x[1],x[3],x[4],x[6],[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],x[15],x[16],x[17],x[20]))\n",
    "cat_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "126167a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decribe function or few analysis seems better, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b821c3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7043"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data.count() #frequence, distinct,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fcf34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions \n",
    "# Module for changing string to int\n",
    "def string_to_int(val):\n",
    "    try:\n",
    "        return int(float(val))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Module getting the count\n",
    "def count(x):\n",
    "    temp=0\n",
    "    for val in list(x):\n",
    "        temp = temp + val[1]\n",
    "        out = str(val[0])+\",\"+str(temp)\n",
    "    return (out)\n",
    "\n",
    "#module for average\n",
    "def mean_val(x):\n",
    "    sums=0\n",
    "    l=0\n",
    "    for i in x:\n",
    "        sums= sums + i[1]\n",
    "        l=l+1\n",
    "        avg=round(sums/l,2)\n",
    "        \n",
    "    return (avg)\n",
    "\n",
    "## module for replace value\n",
    "def replace(column_val):\n",
    "    if column_val==\"Month-to-month\":\n",
    "        column_val=\"1m\"\n",
    "    elif column_val==\"One year\":\n",
    "        column_val=\"1y\"\n",
    "    elif column_val==\"Two year\":\n",
    "        column_val=\"2y\"\n",
    "    else:\n",
    "        column_val= \"Others\"\n",
    "    return column_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43488af",
   "metadata": {},
   "source": [
    "### 4 .Unique customer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1331c4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7590-VHVEG,1', '5575-GNVDE,34', '3668-QPYBK,2', '7795-CFOCW,45']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_customer = data.filter(lambda line: line != header).\\\n",
    "            map(lambda line: line.split(\",\")).map(\n",
    "    lambda x: ((x[0]), string_to_int(x[5]))).\\\n",
    "    groupBy(lambda x: x[0]).\\\n",
    "    map(lambda x: (count(x[1]))).coalesce(1)\n",
    "\n",
    "cat_customer.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f50db7",
   "metadata": {},
   "source": [
    "### 5. -GroupBy contract and avg of totalcharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8f8906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1m', 29), ('1y', 1889)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step4=step3.map(lambda x: (x[15],x[19]))\n",
    "step4.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "604a3f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1m', 1368.79), ('1y', 3032.14), ('2y', 3706.47)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groupby contract and avg totalcharges   \n",
    "def mean_val(x):\n",
    "    sums=0\n",
    "    l=0\n",
    "    for i in x:\n",
    "        sums= sums + i[1]\n",
    "        l=l+1\n",
    "        avg=round(sums/l,2)\n",
    "        \n",
    "    return (avg)\n",
    "    \n",
    "step5= step4.map(lambda x:((x[0]),string_to_int(x[1])))\\\n",
    "            .map(lambda x: (x[0],x[1]))\\\n",
    "            .groupBy(lambda x: (x[0])).\\\n",
    "            map(lambda x: (x[0],mean_val(x[1]))).coalesce(1)\n",
    "\n",
    "           \n",
    "step5.collect() \n",
    "##step5.saveAsTextFile(\"data/avg_totalCharges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ff611",
   "metadata": {},
   "source": [
    "### 6. using accumulator add the totalcharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91c2427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16052864\n",
      "16052864\n",
      "7043\n"
     ]
    }
   ],
   "source": [
    "totalcharges=step4.map(lambda x: x[1])\n",
    "totalcharges.take(5)\n",
    "accum=spark.sparkContext.accumulator(0)\n",
    "totalcharges.foreach(lambda x:accum.add(x))\n",
    "print(accum.value)\n",
    "\n",
    "accuSum=spark.sparkContext.accumulator(0)\n",
    "def countFun(x):\n",
    "    global accuSum\n",
    "    accuSum+=x\n",
    "totalcharges.foreach(countFun)\n",
    "print(accuSum.value)\n",
    "\n",
    "accumCount=spark.sparkContext.accumulator(0)\n",
    "totalcharges.foreach(lambda x:accumCount.add(1))\n",
    "print(accumCount.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4721d0",
   "metadata": {},
   "source": [
    "### 7.Load: Save analysis report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ece2de",
   "metadata": {},
   "source": [
    "GroupBy contract and avg of totalcharges save as files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "678ed59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step5.saveAsTextFile(\"Report/avg_totalCharges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcf3ba",
   "metadata": {},
   "source": [
    "referencs\n",
    "\n",
    "https://www.nbshare.io/notebook/403283317/How-To-Analyze-Data- Using-Pyspark-RDD/\n",
    "\n",
    "https://github.com/sathishmtech01/pyspark_learning/blob/master/scripts/spark/project/main_file.py\n",
    "\n",
    "https://youtu.be/ou0MYgLnftg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668eabd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
